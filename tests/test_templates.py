"""
æµ‹è¯•Promptæ¨¡æ¿æ•ˆæœ
è¿è¡Œ: python tests/test_prompts.py
"""
import os
import sys
import json
import re
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from src.prompts.templates import PromptTemplates

load_dotenv()

api_key = os.getenv("DEEPSEEK_API_KEY")
if not api_key:
    raise ValueError("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®DEEPSEEK_API_KEY")


def test_outline_generation():
    """æµ‹è¯•å¤§çº²ç”Ÿæˆ"""
    print("=" * 70)
    print("æµ‹è¯•1: å¤§çº²ç”ŸæˆPrompt")
    print("=" * 70)

    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")

    # æµ‹è¯•ä¸åŒä¸»é¢˜å’Œé£æ ¼
    test_cases = [
        {
            "topic": "å¦‚ä½•æˆä¸ºä¸€åAI Agentåº”ç”¨å·¥ç¨‹å¸ˆ",
            "num_slides": 6,
            "style": "professional"
        }
        # },
        # {
        #     "topic": "å¦‚ä½•å¼€å§‹ä½ çš„ç¬¬ä¸€ä¸ªåˆ›ä¸šé¡¹ç›®",
        #     "num_slides": 10,
        #     "style": "startup"
        # },
        # {
        #     "topic": "Pythonç¼–ç¨‹åŸºç¡€å…¥é—¨",
        #     "num_slides": 12,
        #     "style": "teaching"
        # }
    ]

    for i, test in enumerate(test_cases, 1):
        print(f"\nğŸ“ æµ‹è¯•æ¡ˆä¾‹ {i}:")
        print(f"   ä¸»é¢˜: {test['topic']}")
        print(f"   é¡µæ•°: {test['num_slides']}")
        print(f"   é£æ ¼: {test['style']}")
        print("-" * 70)

        system_prompt, user_prompt = PromptTemplates.create_outline_prompt(
            test['topic'],
            test['num_slides'],
            test['style']
        )

        try:
            response = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "deepseek-chat"),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=2048,
                temperature=0.7
            )

            response_text = response.choices[0].message.content.strip()
            response_text = re.sub(r'^```json\s*|\s*```$', '', response_text, flags=re.MULTILINE)

            outline = json.loads(response_text)

            print(f"âœ… ç”ŸæˆæˆåŠŸ!")
            print(f"   æ ‡é¢˜: {outline['title']}")
            print(f"   é¡µæ•°: {len(outline['slides'])}")
            print(f"\n   å¤§çº²é¢„è§ˆ:")
            for slide in outline['slides'][:3]:
                print(f"      ç¬¬{slide['page']}é¡µ: {slide['title']} ({slide['type']})")
            if len(outline['slides']) > 3:
                print(f"      ...")
                last = outline['slides'][-1]
                print(f"      ç¬¬{last['page']}é¡µ: {last['title']} ({last['type']})")

            # ä¿å­˜ç»“æœ
            output_dir = "output/test_prompts"
            os.makedirs(output_dir, exist_ok=True)
            with open(f"{output_dir}/outline_{i}.json", "w", encoding="utf-8") as f:
                json.dump(outline, f, ensure_ascii=False, indent=2)

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
            continue

        print()


def test_content_generation():
    """æµ‹è¯•å†…å®¹ç”Ÿæˆ"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•2: å†…å®¹ç”ŸæˆPrompt")
    print("=" * 70)

    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")

    # è¯»å–æ‰€æœ‰outline JSONæ–‡ä»¶
    outline_dir = Path("output/test_prompts")
    outline_files = sorted(outline_dir.glob("outline_*.json"))

    if not outline_files:
        print(f"âŒ åœ¨ {outline_dir} ç›®å½•ä¸­æœªæ‰¾åˆ°outline_*.jsonæ–‡ä»¶")
        return

    # è¯»å–æœ€åä¸€ä¸ªoutlineæ–‡ä»¶ä½œä¸ºç¤ºä¾‹
    outline_file = outline_files[-1]
    print(f"\nğŸ“‚ ä»æ–‡ä»¶åŠ è½½: {outline_file.name}")

    with open(outline_file, 'r', encoding='utf-8') as f:
        outline_data = json.load(f)

    overall_topic = outline_data['title']
    print(f"\nğŸ“‹ æ¼”ç¤ºä¸»é¢˜: {overall_topic}")
    print(f"ğŸ“‹ å‰¯æ ‡é¢˜: {outline_data.get('subtitle', '')}")

    # åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨æ‰€æœ‰ç”Ÿæˆçš„å†…å®¹
    all_content = {
        "title": overall_topic,
        "subtitle": outline_data.get('subtitle', ''),
        "total_pages": len(outline_data['slides']),
        "slides": []
    }

    # éå†æ‰€æœ‰å¹»ç¯ç‰‡ï¼ˆåŒ…æ‹¬å°é¢é¡µå’Œæ€»ç»“é¡µï¼‰
    all_slides = outline_data['slides']

    for slide_info in all_slides:
        print(f"\n" + "-" * 70)
        print(f"ğŸ“ å¤„ç†é¡µé¢ {slide_info['page']}:")
        print(f"   æ ‡é¢˜: {slide_info['title']}")
        print(f"   ç±»å‹: {slide_info['type']}")

        # å¯¹äºå°é¢é¡µå’Œæ€»ç»“é¡µï¼Œç›´æ¥æ·»åŠ åŸºæœ¬ä¿¡æ¯ï¼Œä¸éœ€è¦ç”Ÿæˆå†…å®¹
        if slide_info['type'] in ['cover', 'conclusion']:
            slide_content = {
                "page": slide_info['page'],
                "type": slide_info['type'],
                "title": slide_info['title'],
                "description": slide_info['description']
            }
            all_content["slides"].append(slide_content)
            print(f"   âœ… å·²æ·»åŠ  {slide_info['type']} é¡µ")
            continue

        print(f"   æè¿°: {slide_info['description']}")
        print("-" * 70)

        system_prompt = PromptTemplates.SYSTEM_CONTENT_WRITER
        user_prompt = PromptTemplates.get_content_prompt(
            slide_info['title'],
            slide_info['description'],
            overall_topic,
            slide_info['page'],
            len(outline_data['slides']),
            "professional"
        )

        try:
            response = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "deepseek-chat"),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1024,
                temperature=0.7
            )

            response_text = response.choices[0].message.content.strip()
            response_text = re.sub(r'^```json\s*|\s*```$', '', response_text, flags=re.MULTILINE)

            content = json.loads(response_text)

            # æ·»åŠ é¡µé¢ä¿¡æ¯
            content['page'] = slide_info['page']
            content['type'] = slide_info['type']
            all_content["slides"].append(content)

            print(f"âœ… å†…å®¹ç”ŸæˆæˆåŠŸ!")
            print(f"\n   æ ‡é¢˜: {content['title']}")
            print(f"   è¦ç‚¹:")
            for i, point in enumerate(content['content'], 1):
                print(f"      {i}. {point}")
            if 'notes' in content:
                print(f"\n   å¤‡æ³¨: {content['notes']}")

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
            # å³ä½¿ç”Ÿæˆå¤±è´¥ï¼Œä¹Ÿä¿ç•™åŸºæœ¬ä¿¡æ¯
            slide_content = {
                "page": slide_info['page'],
                "type": slide_info['type'],
                "title": slide_info['title'],
                "description": slide_info['description'],
                "content": [],
                "error": str(e)
            }
            all_content["slides"].append(slide_content)
            continue

    # ä¿å­˜æ‰€æœ‰å†…å®¹åˆ°ä¸€ä¸ªJSONæ–‡ä»¶
    output_dir = "output/test_prompts"
    os.makedirs(output_dir, exist_ok=True)
    output_filename = f"{output_dir}/complete_content_{outline_file.stem}.json"

    with open(output_filename, "w", encoding="utf-8") as f:
        json.dump(all_content, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 70)
    print(f"âœ… æ‰€æœ‰å†…å®¹å·²ä¿å­˜åˆ°: {output_filename}")
    print(f"   æ€»å…±å¤„ç†äº† {len(all_content['slides'])} é¡µå¹»ç¯ç‰‡")
    print("=" * 70)


def test_different_styles():
    """æµ‹è¯•ä¸åŒé£æ ¼çš„æ•ˆæœ"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•3: ä¸åŒé£æ ¼å¯¹æ¯”")
    print("=" * 70)

    topic = "åŒºå—é“¾æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨"
    styles = ["professional", "creative", "academic", "startup"]

    for style in styles:
        print(f"\nğŸ¨ é£æ ¼: {style}")
        print("-" * 70)

        guidelines = PromptTemplates.get_style_guidelines(style)
        print(f"   è¯­è°ƒ: {guidelines['tone']}")
        print(f"   è¯­è¨€: {guidelines['language']}")
        print(f"   ç»“æ„: {guidelines['structure']}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª Promptæ¨¡æ¿æµ‹è¯•å¥—ä»¶")
    print()

    # æµ‹è¯•1: å¤§çº²ç”Ÿæˆ
    test_outline_generation()

    # æµ‹è¯•2: å†…å®¹ç”Ÿæˆ
    test_content_generation()

    # æµ‹è¯•3: é£æ ¼å¯¹æ¯”
    # test_different_styles()

    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print("   æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶: output/test_prompts/")
    print("=" * 70)


if __name__ == "__main__":
    main()
