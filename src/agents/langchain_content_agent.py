"""
åŸºäº LangChain çš„å†…å®¹ç”Ÿæˆ Agent
æä¾›æ›´å¥½çš„æç¤ºè¯ç®¡ç†å’Œé“¾å¼è°ƒç”¨èƒ½åŠ›
"""
from typing import Dict, List, Optional, Any
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langchain_community.chat_message_histories import ChatMessageHistory

from prompts.templates import PromptTemplates


class LangChainContentAgent:
    """åŸºäº LangChain çš„å†…å®¹ç”Ÿæˆ Agent"""

    def __init__(
        self,
        api_key: str,
        model: str = "deepseek-chat",
        base_url: str = "https://api.deepseek.com",
        temperature: float = 0.7,
        max_retries: int = 3
    ):
        """
        åˆå§‹åŒ– LangChain Content Agent

        Args:
            api_key: APIå¯†é’¥
            model: æ¨¡å‹åç§°
            base_url: APIåŸºç¡€URL
            temperature: æ¸©åº¦å‚æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.model = model
        self.temperature = temperature
        self.max_retries = max_retries

        # åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            model=model,
            api_key=api_key,
            base_url=base_url,
            temperature=temperature,
            max_retries=max_retries
        )

        # ä¿å­˜æœ€åç”Ÿæˆçš„å†…å®¹
        self.last_outline = None
        self.last_contents = None

        # åˆå§‹åŒ–å¯¹è¯è®°å¿†
        self.memory = ChatMessageHistory()

        # åˆ›å»ºæç¤ºè¯æ¨¡æ¿
        self._create_prompts()

    def _create_prompts(self):
        """åˆ›å»ºå„ç§æç¤ºè¯æ¨¡æ¿"""

        # å¤§çº²ç”Ÿæˆæç¤ºè¯
        self.outline_prompt = ChatPromptTemplate.from_messages([
            ("system", PromptTemplates.SYSTEM_OUTLINE_DESIGNER),
            ("human", "{user_prompt}")
        ])

        # å†…å®¹ç”Ÿæˆæç¤ºè¯
        self.content_prompt = ChatPromptTemplate.from_messages([
            ("system", PromptTemplates.SYSTEM_CONTENT_WRITER),
            ("human", "{user_prompt}")
        ])

        # å†…å®¹ä¿®æ”¹æç¤ºè¯
        self.modification_prompt = ChatPromptTemplate.from_messages([
            ("system", PromptTemplates.SYSTEM_CONTENT_WRITER),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{modification_request}")
        ])

        # ç»“æŸé¡µæç¤ºè¯
        self.conclusion_prompt = ChatPromptTemplate.from_messages([
            ("system", PromptTemplates.SYSTEM_CONTENT_WRITER),
            ("human", "{user_prompt}")
        ])

        # è¾“å‡ºè§£æå™¨
        self.json_parser = JsonOutputParser()

    def generate_outline(
        self,
        topic: str,
        num_slides: int = 10,
        style: str = "professional"
    ) -> Dict:
        """
        ä½¿ç”¨ LangChain ç”Ÿæˆå¤§çº²

        Args:
            topic: PPTä¸»é¢˜
            num_slides: é¡µæ•°
            style: é£æ ¼

        Returns:
            å¤§çº²å­—å…¸
        """
        print(f"ğŸ¤– LangChain ç”Ÿæˆå¤§çº²: {topic} ({num_slides}é¡µ, {style}é£æ ¼)")

        # åˆ›å»ºç”¨æˆ·æç¤ºè¯
        _, user_prompt = PromptTemplates.create_outline_prompt(topic, num_slides, style)

        # åˆ›å»ºé“¾
        chain = (
            {"user_prompt": RunnablePassthrough()}
            | self.outline_prompt
            | self.llm
            | self.json_parser
        )

        try:
            # æ‰§è¡Œé“¾
            outline = chain.invoke(user_prompt)

            # éªŒè¯å¤§çº²æ ¼å¼
            self._validate_outline(outline, num_slides)

            print(f"âœ… å¤§çº²ç”ŸæˆæˆåŠŸ: {outline['title']}")
            self.last_outline = outline
            return outline

        except Exception as e:
            print(f"âš ï¸ å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise

    async def generate_outline_async(
        self,
        topic: str,
        num_slides: int = 10,
        style: str = "professional"
    ) -> Dict:
        """å¼‚æ­¥ç”Ÿæˆå¤§çº²"""
        print(f"ğŸ¤– LangChain å¼‚æ­¥ç”Ÿæˆå¤§çº²: {topic}")

        _, user_prompt = PromptTemplates.create_outline_prompt(topic, num_slides, style)

        chain = (
            {"user_prompt": RunnablePassthrough()}
            | self.outline_prompt
            | self.llm
            | self.json_parser
        )

        try:
            outline = await chain.ainvoke(user_prompt)
            self._validate_outline(outline, num_slides)
            self.last_outline = outline
            return outline
        except Exception as e:
            print(f"âš ï¸ å¼‚æ­¥å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise

    def generate_slide_content(
        self,
        slide_info: Dict,
        overall_topic: str,
        total_pages: int,
        style: str = "professional"
    ) -> Dict:
        """
        ç”Ÿæˆå•é¡µå†…å®¹

        Args:
            slide_info: é¡µé¢ä¿¡æ¯
            overall_topic: æ•´ä½“ä¸»é¢˜
            total_pages: æ€»é¡µæ•°
            style: é£æ ¼

        Returns:
            å†…å®¹å­—å…¸
        """
        slide_type = slide_info.get("type", "content")
        page_num = slide_info.get("page", 1)

        print(f"   ğŸ“ ç¬¬{page_num}é¡µ: {slide_info.get('title', '')}")

        if slide_type == "cover":
            return self._generate_cover_content(slide_info, overall_topic)
        elif slide_type == "conclusion":
            return self._generate_conclusion_content(slide_info, overall_topic, total_pages)
        else:
            return self._generate_content_page(slide_info, overall_topic, total_pages, style)

    async def generate_slide_content_async(
        self,
        slide_info: Dict,
        overall_topic: str,
        total_pages: int,
        style: str = "professional"
    ) -> Dict:
        """å¼‚æ­¥ç”Ÿæˆå•é¡µå†…å®¹"""
        slide_type = slide_info.get("type", "content")

        if slide_type == "cover":
            return self._generate_cover_content(slide_info, overall_topic)
        elif slide_type == "conclusion":
            return await self._generate_conclusion_content_async(
                slide_info, overall_topic, total_pages
            )
        else:
            return await self._generate_content_page_async(
                slide_info, overall_topic, total_pages, style
            )

    def _generate_cover_content(self, slide_info: Dict, topic: str) -> Dict:
        """ç”Ÿæˆå°é¢é¡µå†…å®¹"""
        return {
            "title": slide_info.get("title", topic),
            "subtitle": slide_info.get("description", f"å…³äº{topic}çš„æ·±å…¥æ¢è®¨"),
            "page_number": 1,
            "content": [],
            "type": "cover"
        }

    def _generate_conclusion_content(self, slide_info: Dict, topic: str, total_pages: int) -> Dict:
        """ç”Ÿæˆç»“æŸé¡µå†…å®¹"""
        user_prompt = PromptTemplates.get_conclusion_prompt(
            topic,
            [],  # å¯ä»¥ä¼ å…¥å…³é”®è¦ç‚¹
            total_pages
        )

        chain = (
            {"user_prompt": RunnablePassthrough()}
            | self.conclusion_prompt
            | self.llm
            | self.json_parser
        )

        try:
            content = chain.invoke(user_prompt)
            content["type"] = "conclusion"
            return content
        except Exception as e:
            print(f"      âš ï¸ ä½¿ç”¨é»˜è®¤ç»“æŸé¡µ: {str(e)}")
            return {
                "title": slide_info.get("title", "è°¢è°¢"),
                "content": ["æ„Ÿè°¢æ‚¨çš„è†å¬", "æ¬¢è¿æé—®ä¸äº¤æµ"],
                "type": "conclusion"
            }

    async def _generate_conclusion_content_async(
        self, slide_info: Dict, topic: str, total_pages: int
    ) -> Dict:
        """å¼‚æ­¥ç”Ÿæˆç»“æŸé¡µå†…å®¹"""
        user_prompt = PromptTemplates.get_conclusion_prompt(
            topic, [], total_pages
        )

        chain = (
            {"user_prompt": RunnablePassthrough()}
            | self.conclusion_prompt
            | self.llm
            | self.json_parser
        )

        try:
            content = await chain.ainvoke(user_prompt)
            content["type"] = "conclusion"
            return content
        except Exception as e:
            print(f"      âš ï¸ ä½¿ç”¨é»˜è®¤ç»“æŸé¡µ: {str(e)}")
            return {
                "title": slide_info.get("title", "è°¢è°¢"),
                "content": ["æ„Ÿè°¢æ‚¨çš„è†å¬", "æ¬¢è¿æé—®ä¸äº¤æµ"],
                "type": "conclusion"
            }

    def _generate_content_page(
        self,
        slide_info: Dict,
        overall_topic: str,
        total_pages: int,
        style: str
    ) -> Dict:
        """ç”Ÿæˆå†…å®¹é¡µ"""
        system_prompt, user_prompt = PromptTemplates.create_content_prompt(
            slide_info, overall_topic, total_pages, style
        )

        # ä½¿ç”¨è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", user_prompt)
        ])

        chain = (
            {"user_prompt": RunnablePassthrough()}
            | prompt
            | self.llm
            | self.json_parser
        )

        try:
            content = chain.invoke("")
            content["type"] = "content"
            return content
        except Exception as e:
            print(f"      âš ï¸ ä½¿ç”¨é»˜è®¤å†…å®¹: {str(e)}")
            return {
                "title": slide_info.get("title", ""),
                "content": ["å†…å®¹ç”Ÿæˆä¸­...", "è¯·ç¨å€™..."],
                "type": "content"
            }

    async def _generate_content_page_async(
        self,
        slide_info: Dict,
        overall_topic: str,
        total_pages: int,
        style: str
    ) -> Dict:
        """å¼‚æ­¥ç”Ÿæˆå†…å®¹é¡µ"""
        system_prompt, user_prompt = PromptTemplates.create_content_prompt(
            slide_info, overall_topic, total_pages, style
        )

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", user_prompt)
        ])

        chain = (
            {"user_prompt": RunnablePassthrough()}
            | prompt
            | self.llm
            | self.json_parser
        )

        try:
            content = await chain.ainvoke("")
            content["type"] = "content"
            return content
        except Exception as e:
            print(f"      âš ï¸ ä½¿ç”¨é»˜è®¤å†…å®¹: {str(e)}")
            return {
                "title": slide_info.get("title", ""),
                "content": ["å†…å®¹ç”Ÿæˆä¸­...", "è¯·ç¨å€™..."],
                "type": "content"
            }

    def modify_content(
        self,
        original_content: Dict,
        modification_request: str
    ) -> Dict:
        """
        ä¿®æ”¹å†…å®¹ï¼ˆå¸¦å¯¹è¯è®°å¿†ï¼‰

        Args:
            original_content: åŸå§‹å†…å®¹
            modification_request: ä¿®æ”¹è¦æ±‚

        Returns:
            ä¿®æ”¹åçš„å†…å®¹
        """
        print(f"ğŸ”„ LangChain ä¿®æ”¹å†…å®¹: {modification_request}")

        # è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼
        self.memory.add_user_message(
            f"åŸå§‹å†…å®¹: {original_content}"
        )
        self.memory.add_ai_message(
            f"å·²ç†è§£åŸå§‹å†…å®¹"
        )

        chain = (
            {
                "modification_request": RunnablePassthrough(),
                "chat_history": lambda x: self.memory.messages
            }
            | self.modification_prompt
            | self.llm
            | self.json_parser
        )

        try:
            modified_content = chain.invoke(modification_request)

            # æ›´æ–°è®°å¿†
            self.memory.add_user_message(modification_request)
            self.memory.add_ai_message(
                f"å·²ä¿®æ”¹å†…å®¹: {modified_content}"
            )

            print(f"âœ… å†…å®¹ä¿®æ”¹å®Œæˆ")
            return modified_content

        except Exception as e:
            print(f"âŒ ä¿®æ”¹å¤±è´¥: {str(e)}")
            return original_content

    def generate_batch_contents(
        self,
        slides_info: List[Dict],
        overall_topic: str,
        total_pages: int,
        style: str = "professional"
    ) -> List[Dict]:
        """
        æ‰¹é‡ç”Ÿæˆå†…å®¹ï¼ˆä½¿ç”¨å¹¶è¡Œå¤„ç†ï¼‰

        Args:
            slides_info: é¡µé¢ä¿¡æ¯åˆ—è¡¨
            overall_topic: æ•´ä½“ä¸»é¢˜
            total_pages: æ€»é¡µæ•°
            style: é£æ ¼

        Returns:
            å†…å®¹åˆ—è¡¨
        """
        from langchain.schema.runnable import RunnableParallel

        print(f"ğŸš€ å¹¶è¡Œç”Ÿæˆ {len(slides_info)} é¡µå†…å®¹...")

        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        tasks = []
        for slide_info in slides_info:
            task = {
                "slide_info": slide_info,
                "generate": RunnablePassthrough.assign(
                    content=lambda x: self.generate_slide_content(
                        x["slide_info"],
                        overall_topic,
                        total_pages,
                        style
                    )
                )
            }
            tasks.append(task)

        # æ‰§è¡Œå¹¶è¡Œä»»åŠ¡
        try:
            results = []
            for slide_info in slides_info:
                content = self.generate_slide_content(
                    slide_info, overall_topic, total_pages, style
                )
                results.append(content)

            self.last_contents = results
            return results

        except Exception as e:
            print(f"âš ï¸ æ‰¹é‡ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise

    async def generate_batch_contents_async(
        self,
        slides_info: List[Dict],
        overall_topic: str,
        total_pages: int,
        style: str = "professional"
    ) -> List[Dict]:
        """å¼‚æ­¥æ‰¹é‡ç”Ÿæˆå†…å®¹"""
        import asyncio

        tasks = [
            self.generate_slide_content_async(
                slide_info, overall_topic, total_pages, style
            )
            for slide_info in slides_info
        ]

        try:
            results = await asyncio.gather(*tasks)
            self.last_contents = results
            return results
        except Exception as e:
            print(f"âš ï¸ å¼‚æ­¥æ‰¹é‡ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise

    def _validate_outline(self, outline: Dict, expected_slides: int) -> None:
        """éªŒè¯å¤§çº²æ ¼å¼"""
        if "title" not in outline:
            raise ValueError("å¤§çº²ç¼ºå°‘titleå­—æ®µ")

        if "slides" not in outline or not isinstance(outline["slides"], list):
            raise ValueError("å¤§çº²ç¼ºå°‘slidesæ•°ç»„")

        if len(outline["slides"]) < expected_slides - 2:
            print(f"âš ï¸ è­¦å‘Š: ç”Ÿæˆçš„é¡µæ•°({len(outline['slides'])})å°‘äºé¢„æœŸ({expected_slides})")

        if outline["slides"][0].get("type") != "cover":
            print("âš ï¸ è­¦å‘Š: ç¬¬ä¸€é¡µä¸æ˜¯å°é¢é¡µ")

        if outline["slides"][-1].get("type") != "conclusion":
            print("âš ï¸ è­¦å‘Š: æœ€åä¸€é¡µä¸æ˜¯ç»“æŸé¡µ")